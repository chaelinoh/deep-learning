{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1Dh97H8gjh1ZERky0/YBE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaelinoh/deep-learning/blob/main/keras)_%EA%B0%9C_%EA%B3%A0%EC%96%91%EC%9D%B4_%EA%B5%AC%EB%B6%84%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80b9vJOejdjv",
        "outputId": "8f6c1966-f946-4649-ec95-4196630f63e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats-redux-kernels-edition.zip to /content\n",
            " 99% 806M/814M [00:06<00:00, 95.4MB/s]\n",
            "100% 814M/814M [00:06<00:00, 123MB/s] \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip -d ."
      ],
      "metadata": {
        "id": "X6dqIBK-krhl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "s8TLyPjSlH4i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import shutil\n",
        "\n",
        "os.mkdir('/content/dataset')\n",
        "os.mkdir('/content/dataset/cat')\n",
        "os.mkdir('/content/dataset/dog')\n",
        "\n",
        "#개,고양이 사진 각 폴더로 복사\n",
        "for i in os.listdir('/content/train/'):\n",
        "  if 'cat' in i:\n",
        "    shutil.copyfile('/content/train/' + i,'/content/dataset/cat/'+i)\n",
        "  if 'dog' in i:\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/dog/'+i)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p83lYs9eus2i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.keras 사용해서 이미지 숫자화\n",
        "#tf.keras.preprocessing.image_dataset_from_directory()\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64,64),  #모든 이미지를 64*64픽셀로 변경\n",
        "    batch_size = 64,     #한번에 모든 이미지를 넣지 않고 64개씩 뽑아서 돌려보기 위함\n",
        "    subset='training',   #데이터의 80%\n",
        "    validation_split=0.2,   \n",
        "    seed=1234\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64,64),  #모든 이미지를 64*64픽셀로 변경\n",
        "    batch_size = 64,     #한번에 모든 이미지를 넣지 않고 64개씩 뽑아서 돌려보기 위함\n",
        "    subset='validation',\n",
        "    validation_split=0.2,   #데이터의 20%\n",
        "    seed=1234\n",
        ")\n",
        "\n",
        "print(train_ds)\n",
        "\n",
        "#데이터 전처리. 인풋 데이터 0~1 사이로 압축하기\n",
        "\n",
        "def 전처리함수(i, 정답):\n",
        "  i = tf.cast(i/255.0, tf.float32)\n",
        "  return i, 정답\n",
        "\n",
        "train_ds = train_ds.map(전처리함수)\n",
        "val_ds = val_ds.map(전처리함수)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i, 정답 in train_ds.take(1):\n",
        "  print(i)\n",
        "  print(정답)\n",
        "  plt.imshow(i[0].numpy().astype('uint8'))\n",
        "  plt.show()\n",
        "  \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "u9KUAR3g4voT",
        "outputId": "a274d936-94e5-4841-ae28-5156e9af97be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport matplotlib.pyplot as plt\\n\\nfor i, 정답 in train_ds.take(1):\\n  print(i)\\n  print(정답)\\n  plt.imshow(i[0].numpy().astype('uint8'))\\n  plt.show()\\n  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델만들기\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(64,64,3)), #칼라사진이라 (_,_,3)\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Dropout(0.2), #dropout fpdldj(overfitting 완화 가능)\n",
        "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),  #0~1 사이 확률값 출력\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdgc2Kj38Plh",
        "outputId": "572d30c4-df45-4277-9443-20ee9f968043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,142,081\n",
            "Trainable params: 1,142,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "313/313 [==============================] - 238s 757ms/step - loss: 0.5987 - accuracy: 0.6558 - val_loss: 0.5230 - val_accuracy: 0.7426\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 239s 763ms/step - loss: 0.4851 - accuracy: 0.7626 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 236s 753ms/step - loss: 0.4216 - accuracy: 0.8056 - val_loss: 0.4566 - val_accuracy: 0.8018\n",
            "Epoch 4/5\n",
            "181/313 [================>.............] - ETA: 1:31 - loss: 0.3898 - accuracy: 0.8212"
          ]
        }
      ]
    }
  ]
}